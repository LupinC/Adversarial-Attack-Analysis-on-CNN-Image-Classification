Epoch 1: Train Loss: 1.5577, Test Loss: 1.3566, Test Acc: 0.5000
Epoch 2: Train Loss: 1.2729, Test Loss: 1.2527, Test Acc: 0.5495
Epoch 3: Train Loss: 1.1350, Test Loss: 1.4316, Test Acc: 0.4910
Epoch 4: Train Loss: 1.0423, Test Loss: 1.0445, Test Acc: 0.6267
Epoch 5: Train Loss: 0.9702, Test Loss: 1.0846, Test Acc: 0.6221
Epoch 6: Train Loss: 0.9072, Test Loss: 0.9415, Test Acc: 0.6687
Epoch 7: Train Loss: 0.8507, Test Loss: 1.0923, Test Acc: 0.6191
Epoch 8: Train Loss: 0.8120, Test Loss: 0.9854, Test Acc: 0.6526
Epoch 9: Train Loss: 0.7677, Test Loss: 0.8464, Test Acc: 0.7016
Epoch 10: Train Loss: 0.7392, Test Loss: 0.8664, Test Acc: 0.6922
Epoch 11: Train Loss: 0.7137, Test Loss: 0.9279, Test Acc: 0.6815
Epoch 12: Train Loss: 0.6842, Test Loss: 0.7690, Test Acc: 0.7385
Epoch 13: Train Loss: 0.6581, Test Loss: 0.7502, Test Acc: 0.7388
Epoch 14: Train Loss: 0.6412, Test Loss: 0.8435, Test Acc: 0.7172
Epoch 15: Train Loss: 0.6227, Test Loss: 0.7262, Test Acc: 0.7536
Epoch 16: Train Loss: 0.5995, Test Loss: 0.6999, Test Acc: 0.7553
Epoch 17: Train Loss: 0.5829, Test Loss: 0.8295, Test Acc: 0.7257
Epoch 18: Train Loss: 0.5674, Test Loss: 0.8852, Test Acc: 0.6866
Epoch 19: Train Loss: 0.5492, Test Loss: 0.8367, Test Acc: 0.7151
Epoch 20: Train Loss: 0.5337, Test Loss: 0.6518, Test Acc: 0.7730
Epoch 21: Train Loss: 0.5257, Test Loss: 0.6724, Test Acc: 0.7686
Epoch 22: Train Loss: 0.5087, Test Loss: 0.6392, Test Acc: 0.7751
Epoch 23: Train Loss: 0.4964, Test Loss: 0.8295, Test Acc: 0.7082
Epoch 24: Train Loss: 0.4822, Test Loss: 0.7116, Test Acc: 0.7630
Epoch 25: Train Loss: 0.4726, Test Loss: 0.6954, Test Acc: 0.7659
Epoch 26: Train Loss: 0.4616, Test Loss: 0.6493, Test Acc: 0.7764
Epoch 27: Train Loss: 0.4487, Test Loss: 0.8723, Test Acc: 0.7198
Epoch 28: Train Loss: 0.4337, Test Loss: 0.6178, Test Acc: 0.7908
Epoch 29: Train Loss: 0.4339, Test Loss: 0.6472, Test Acc: 0.7826
Epoch 30: Train Loss: 0.4203, Test Loss: 0.6181, Test Acc: 0.7894
Epoch 31: Train Loss: 0.3495, Test Loss: 0.5399, Test Acc: 0.8218
Epoch 32: Train Loss: 0.3286, Test Loss: 0.5328, Test Acc: 0.8202
Epoch 33: Train Loss: 0.3239, Test Loss: 0.5309, Test Acc: 0.8203
Epoch 34: Train Loss: 0.3162, Test Loss: 0.5370, Test Acc: 0.8188
Epoch 35: Train Loss: 0.3170, Test Loss: 0.5343, Test Acc: 0.8193
Epoch 36: Train Loss: 0.3086, Test Loss: 0.5350, Test Acc: 0.8217
Epoch 37: Train Loss: 0.3081, Test Loss: 0.5404, Test Acc: 0.8179
Epoch 38: Train Loss: 0.3049, Test Loss: 0.5377, Test Acc: 0.8208
Epoch 39: Train Loss: 0.3023, Test Loss: 0.5430, Test Acc: 0.8179
Epoch 40: Train Loss: 0.3018, Test Loss: 0.5433, Test Acc: 0.8184
Epoch 41: Train Loss: 0.2996, Test Loss: 0.5545, Test Acc: 0.8155
Epoch 42: Train Loss: 0.2950, Test Loss: 0.5477, Test Acc: 0.8173
Epoch 43: Train Loss: 0.2915, Test Loss: 0.5507, Test Acc: 0.8149
Epoch 44: Train Loss: 0.2927, Test Loss: 0.5487, Test Acc: 0.8160
Epoch 45: Train Loss: 0.2901, Test Loss: 0.5523, Test Acc: 0.8174
Epoch 46: Train Loss: 0.2890, Test Loss: 0.5472, Test Acc: 0.8181
Epoch 47: Train Loss: 0.2871, Test Loss: 0.5506, Test Acc: 0.8168
Epoch 48: Train Loss: 0.2855, Test Loss: 0.5518, Test Acc: 0.8185
Epoch 49: Train Loss: 0.2856, Test Loss: 0.5464, Test Acc: 0.8197
Epoch 50: Train Loss: 0.2803, Test Loss: 0.5517, Test Acc: 0.8183
Epoch 51: Train Loss: 0.2802, Test Loss: 0.5540, Test Acc: 0.8185
Epoch 52: Train Loss: 0.2756, Test Loss: 0.5542, Test Acc: 0.8172
Epoch 53: Train Loss: 0.2793, Test Loss: 0.5693, Test Acc: 0.8141
Epoch 54: Train Loss: 0.2730, Test Loss: 0.5583, Test Acc: 0.8164
Epoch 55: Train Loss: 0.2717, Test Loss: 0.5569, Test Acc: 0.8206
Epoch 56: Train Loss: 0.2746, Test Loss: 0.5559, Test Acc: 0.8198
Epoch 57: Train Loss: 0.2701, Test Loss: 0.5623, Test Acc: 0.8177
Epoch 58: Train Loss: 0.2702, Test Loss: 0.5563, Test Acc: 0.8159
Epoch 59: Train Loss: 0.2707, Test Loss: 0.5529, Test Acc: 0.8185
Epoch 60: Train Loss: 0.2635, Test Loss: 0.5671, Test Acc: 0.8144
Epoch 61: Train Loss: 0.2561, Test Loss: 0.5494, Test Acc: 0.8195
Epoch 62: Train Loss: 0.2610, Test Loss: 0.5478, Test Acc: 0.8189
Epoch 63: Train Loss: 0.2541, Test Loss: 0.5513, Test Acc: 0.8208
Epoch 64: Train Loss: 0.2534, Test Loss: 0.5501, Test Acc: 0.8196
Epoch 65: Train Loss: 0.2532, Test Loss: 0.5546, Test Acc: 0.8198
Epoch 66: Train Loss: 0.2531, Test Loss: 0.5558, Test Acc: 0.8200
Epoch 67: Train Loss: 0.2546, Test Loss: 0.5534, Test Acc: 0.8186
Epoch 68: Train Loss: 0.2551, Test Loss: 0.5512, Test Acc: 0.8190
Epoch 69: Train Loss: 0.2503, Test Loss: 0.5518, Test Acc: 0.8191
Epoch 70: Train Loss: 0.2528, Test Loss: 0.5566, Test Acc: 0.8193
Epoch 71: Train Loss: 0.2537, Test Loss: 0.5537, Test Acc: 0.8201
Epoch 72: Train Loss: 0.2507, Test Loss: 0.5483, Test Acc: 0.8194
Epoch 73: Train Loss: 0.2528, Test Loss: 0.5536, Test Acc: 0.8190
Epoch 74: Train Loss: 0.2517, Test Loss: 0.5543, Test Acc: 0.8192
Epoch 75: Train Loss: 0.2545, Test Loss: 0.5511, Test Acc: 0.8181
Epoch 76: Train Loss: 0.2526, Test Loss: 0.5573, Test Acc: 0.8181
Epoch 77: Train Loss: 0.2516, Test Loss: 0.5519, Test Acc: 0.8170
Epoch 78: Train Loss: 0.2535, Test Loss: 0.5508, Test Acc: 0.8184
Epoch 79: Train Loss: 0.2495, Test Loss: 0.5547, Test Acc: 0.8202
Epoch 80: Train Loss: 0.2523, Test Loss: 0.5551, Test Acc: 0.8197
Epoch 81: Train Loss: 0.2521, Test Loss: 0.5588, Test Acc: 0.8178
Epoch 82: Train Loss: 0.2514, Test Loss: 0.5548, Test Acc: 0.8190
Epoch 83: Train Loss: 0.2557, Test Loss: 0.5635, Test Acc: 0.8182
Epoch 84: Train Loss: 0.2512, Test Loss: 0.5566, Test Acc: 0.8199
Epoch 85: Train Loss: 0.2521, Test Loss: 0.5563, Test Acc: 0.8170
Epoch 86: Train Loss: 0.2518, Test Loss: 0.5525, Test Acc: 0.8182
Epoch 87: Train Loss: 0.2505, Test Loss: 0.5533, Test Acc: 0.8183
Epoch 88: Train Loss: 0.2517, Test Loss: 0.5543, Test Acc: 0.8178
Epoch 89: Train Loss: 0.2526, Test Loss: 0.5562, Test Acc: 0.8181
Epoch 90: Train Loss: 0.2525, Test Loss: 0.5544, Test Acc: 0.8199
Epoch 91: Train Loss: 0.2486, Test Loss: 0.5543, Test Acc: 0.8213
Epoch 92: Train Loss: 0.2506, Test Loss: 0.5562, Test Acc: 0.8188
Epoch 93: Train Loss: 0.2507, Test Loss: 0.5586, Test Acc: 0.8199
Epoch 94: Train Loss: 0.2478, Test Loss: 0.5546, Test Acc: 0.8187
Epoch 95: Train Loss: 0.2486, Test Loss: 0.5558, Test Acc: 0.8181
Epoch 96: Train Loss: 0.2526, Test Loss: 0.5529, Test Acc: 0.8186
Epoch 97: Train Loss: 0.2500, Test Loss: 0.5542, Test Acc: 0.8191
Epoch 98: Train Loss: 0.2501, Test Loss: 0.5562, Test Acc: 0.8177
Epoch 99: Train Loss: 0.2485, Test Loss: 0.5571, Test Acc: 0.8168
Epoch 100: Train Loss: 0.2468, Test Loss: 0.5525, Test Acc: 0.8186
Epoch 101: Train Loss: 0.2481, Test Loss: 0.5593, Test Acc: 0.8186
Epoch 102: Train Loss: 0.2480, Test Loss: 0.5541, Test Acc: 0.8181
Epoch 103: Train Loss: 0.2474, Test Loss: 0.5530, Test Acc: 0.8176
Epoch 104: Train Loss: 0.2513, Test Loss: 0.5545, Test Acc: 0.8175
Epoch 105: Train Loss: 0.2492, Test Loss: 0.5535, Test Acc: 0.8185
Epoch 106: Train Loss: 0.2507, Test Loss: 0.5548, Test Acc: 0.8178
Epoch 107: Train Loss: 0.2494, Test Loss: 0.5643, Test Acc: 0.8196
Epoch 108: Train Loss: 0.2459, Test Loss: 0.5582, Test Acc: 0.8181
Epoch 109: Train Loss: 0.2498, Test Loss: 0.5529, Test Acc: 0.8194
Epoch 110: Train Loss: 0.2468, Test Loss: 0.5568, Test Acc: 0.8190
Epoch 111: Train Loss: 0.2476, Test Loss: 0.5527, Test Acc: 0.8192
Epoch 112: Train Loss: 0.2486, Test Loss: 0.5564, Test Acc: 0.8193
Epoch 113: Train Loss: 0.2504, Test Loss: 0.5564, Test Acc: 0.8168
Epoch 114: Train Loss: 0.2495, Test Loss: 0.5544, Test Acc: 0.8196
Epoch 115: Train Loss: 0.2494, Test Loss: 0.5532, Test Acc: 0.8173
Epoch 116: Train Loss: 0.2495, Test Loss: 0.5552, Test Acc: 0.8174
Epoch 117: Train Loss: 0.2476, Test Loss: 0.5555, Test Acc: 0.8193
Epoch 118: Train Loss: 0.2453, Test Loss: 0.5574, Test Acc: 0.8189
Epoch 119: Train Loss: 0.2491, Test Loss: 0.5548, Test Acc: 0.8197
Epoch 120: Train Loss: 0.2501, Test Loss: 0.5524, Test Acc: 0.8185
Epoch 121: Train Loss: 0.2515, Test Loss: 0.5560, Test Acc: 0.8181
Epoch 122: Train Loss: 0.2478, Test Loss: 0.5577, Test Acc: 0.8179
Epoch 123: Train Loss: 0.2497, Test Loss: 0.5570, Test Acc: 0.8188
Epoch 124: Train Loss: 0.2468, Test Loss: 0.5606, Test Acc: 0.8176
Epoch 125: Train Loss: 0.2478, Test Loss: 0.5553, Test Acc: 0.8185
Epoch 126: Train Loss: 0.2494, Test Loss: 0.5530, Test Acc: 0.8197
Epoch 127: Train Loss: 0.2497, Test Loss: 0.5610, Test Acc: 0.8180
Epoch 128: Train Loss: 0.2520, Test Loss: 0.5549, Test Acc: 0.8182
Epoch 129: Train Loss: 0.2499, Test Loss: 0.5558, Test Acc: 0.8194
Epoch 130: Train Loss: 0.2494, Test Loss: 0.5519, Test Acc: 0.8185
Epoch 131: Train Loss: 0.2500, Test Loss: 0.5577, Test Acc: 0.8193
Epoch 132: Train Loss: 0.2510, Test Loss: 0.5528, Test Acc: 0.8173
Epoch 133: Train Loss: 0.2468, Test Loss: 0.5593, Test Acc: 0.8200
Epoch 134: Train Loss: 0.2487, Test Loss: 0.5588, Test Acc: 0.8191
Epoch 135: Train Loss: 0.2494, Test Loss: 0.5541, Test Acc: 0.8175
Epoch 136: Train Loss: 0.2485, Test Loss: 0.5518, Test Acc: 0.8183
Epoch 137: Train Loss: 0.2511, Test Loss: 0.5526, Test Acc: 0.8166
Epoch 138: Train Loss: 0.2485, Test Loss: 0.5575, Test Acc: 0.8176
Epoch 139: Train Loss: 0.2476, Test Loss: 0.5552, Test Acc: 0.8196
Epoch 140: Train Loss: 0.2528, Test Loss: 0.5606, Test Acc: 0.8189
Epoch 141: Train Loss: 0.2466, Test Loss: 0.5515, Test Acc: 0.8177
Epoch 142: Train Loss: 0.2485, Test Loss: 0.5551, Test Acc: 0.8173
Epoch 143: Train Loss: 0.2513, Test Loss: 0.5565, Test Acc: 0.8175
Epoch 144: Train Loss: 0.2495, Test Loss: 0.5527, Test Acc: 0.8195
Epoch 145: Train Loss: 0.2472, Test Loss: 0.5520, Test Acc: 0.8189
Epoch 146: Train Loss: 0.2484, Test Loss: 0.5613, Test Acc: 0.8172
Epoch 147: Train Loss: 0.2490, Test Loss: 0.5545, Test Acc: 0.8178
Epoch 148: Train Loss: 0.2502, Test Loss: 0.5586, Test Acc: 0.8174
Epoch 149: Train Loss: 0.2478, Test Loss: 0.5601, Test Acc: 0.8186
Epoch 150: Train Loss: 0.2494, Test Loss: 0.5535, Test Acc: 0.8186
Epoch 151: Train Loss: 0.2509, Test Loss: 0.5574, Test Acc: 0.8183
Epoch 152: Train Loss: 0.2488, Test Loss: 0.5574, Test Acc: 0.8190
Epoch 153: Train Loss: 0.2464, Test Loss: 0.5572, Test Acc: 0.8181
Epoch 154: Train Loss: 0.2480, Test Loss: 0.5563, Test Acc: 0.8181
Epoch 155: Train Loss: 0.2502, Test Loss: 0.5515, Test Acc: 0.8193
Epoch 156: Train Loss: 0.2508, Test Loss: 0.5509, Test Acc: 0.8204
Epoch 157: Train Loss: 0.2482, Test Loss: 0.5569, Test Acc: 0.8180
Epoch 158: Train Loss: 0.2495, Test Loss: 0.5564, Test Acc: 0.8175
Epoch 159: Train Loss: 0.2466, Test Loss: 0.5618, Test Acc: 0.8182
Epoch 160: Train Loss: 0.2483, Test Loss: 0.5575, Test Acc: 0.8188
Epoch 161: Train Loss: 0.2493, Test Loss: 0.5585, Test Acc: 0.8172
Epoch 162: Train Loss: 0.2491, Test Loss: 0.5537, Test Acc: 0.8181
Epoch 163: Train Loss: 0.2481, Test Loss: 0.5690, Test Acc: 0.8168
Epoch 164: Train Loss: 0.2463, Test Loss: 0.5549, Test Acc: 0.8184
Epoch 165: Train Loss: 0.2493, Test Loss: 0.5536, Test Acc: 0.8184
Epoch 166: Train Loss: 0.2488, Test Loss: 0.5570, Test Acc: 0.8180
Epoch 167: Train Loss: 0.2490, Test Loss: 0.5565, Test Acc: 0.8173
Epoch 168: Train Loss: 0.2507, Test Loss: 0.5547, Test Acc: 0.8180
Epoch 169: Train Loss: 0.2442, Test Loss: 0.5533, Test Acc: 0.8182
Epoch 170: Train Loss: 0.2485, Test Loss: 0.5601, Test Acc: 0.8189
Epoch 171: Train Loss: 0.2496, Test Loss: 0.5537, Test Acc: 0.8194
Epoch 172: Train Loss: 0.2489, Test Loss: 0.5565, Test Acc: 0.8199
Epoch 173: Train Loss: 0.2480, Test Loss: 0.5570, Test Acc: 0.8193
Epoch 174: Train Loss: 0.2495, Test Loss: 0.5572, Test Acc: 0.8187
Epoch 175: Train Loss: 0.2500, Test Loss: 0.5542, Test Acc: 0.8193
Epoch 176: Train Loss: 0.2504, Test Loss: 0.5557, Test Acc: 0.8187
Epoch 177: Train Loss: 0.2486, Test Loss: 0.5522, Test Acc: 0.8190
Epoch 178: Train Loss: 0.2497, Test Loss: 0.5584, Test Acc: 0.8190
Epoch 179: Train Loss: 0.2463, Test Loss: 0.5518, Test Acc: 0.8186
Epoch 180: Train Loss: 0.2511, Test Loss: 0.5558, Test Acc: 0.8175
Epoch 181: Train Loss: 0.2515, Test Loss: 0.5528, Test Acc: 0.8180
Epoch 182: Train Loss: 0.2496, Test Loss: 0.5523, Test Acc: 0.8201
Epoch 183: Train Loss: 0.2492, Test Loss: 0.5518, Test Acc: 0.8181
Epoch 184: Train Loss: 0.2470, Test Loss: 0.5527, Test Acc: 0.8178
Epoch 185: Train Loss: 0.2497, Test Loss: 0.5529, Test Acc: 0.8182
Epoch 186: Train Loss: 0.2506, Test Loss: 0.5530, Test Acc: 0.8175
Epoch 187: Train Loss: 0.2481, Test Loss: 0.5562, Test Acc: 0.8190
Epoch 188: Train Loss: 0.2460, Test Loss: 0.5537, Test Acc: 0.8182
Epoch 189: Train Loss: 0.2495, Test Loss: 0.5489, Test Acc: 0.8169
Epoch 190: Train Loss: 0.2516, Test Loss: 0.5614, Test Acc: 0.8185
Epoch 191: Train Loss: 0.2481, Test Loss: 0.5518, Test Acc: 0.8196
Epoch 192: Train Loss: 0.2477, Test Loss: 0.5543, Test Acc: 0.8190
Epoch 193: Train Loss: 0.2499, Test Loss: 0.5563, Test Acc: 0.8183
Epoch 194: Train Loss: 0.2487, Test Loss: 0.5571, Test Acc: 0.8187
Epoch 195: Train Loss: 0.2487, Test Loss: 0.5507, Test Acc: 0.8193
Epoch 196: Train Loss: 0.2468, Test Loss: 0.5572, Test Acc: 0.8197
Epoch 197: Train Loss: 0.2485, Test Loss: 0.5594, Test Acc: 0.8179
Epoch 198: Train Loss: 0.2479, Test Loss: 0.5531, Test Acc: 0.8188
Epoch 199: Train Loss: 0.2500, Test Loss: 0.5573, Test Acc: 0.8183
Epoch 200: Train Loss: 0.2475, Test Loss: 0.5580, Test Acc: 0.8180
Epoch 201: Train Loss: 0.2493, Test Loss: 0.5560, Test Acc: 0.8179
Epoch 202: Train Loss: 0.2497, Test Loss: 0.5531, Test Acc: 0.8184
Epoch 203: Train Loss: 0.2503, Test Loss: 0.5540, Test Acc: 0.8179
Epoch 204: Train Loss: 0.2438, Test Loss: 0.5606, Test Acc: 0.8181
Epoch 205: Train Loss: 0.2499, Test Loss: 0.5547, Test Acc: 0.8184
Epoch 206: Train Loss: 0.2490, Test Loss: 0.5592, Test Acc: 0.8184
Epoch 207: Train Loss: 0.2498, Test Loss: 0.5590, Test Acc: 0.8188
Epoch 208: Train Loss: 0.2492, Test Loss: 0.5539, Test Acc: 0.8205
Epoch 209: Train Loss: 0.2488, Test Loss: 0.5577, Test Acc: 0.8172
Epoch 210: Train Loss: 0.2497, Test Loss: 0.5524, Test Acc: 0.8186
Epoch 211: Train Loss: 0.2489, Test Loss: 0.5594, Test Acc: 0.8185
Epoch 212: Train Loss: 0.2526, Test Loss: 0.5546, Test Acc: 0.8185
Epoch 213: Train Loss: 0.2485, Test Loss: 0.5576, Test Acc: 0.8185
Epoch 214: Train Loss: 0.2510, Test Loss: 0.5587, Test Acc: 0.8179
Epoch 215: Train Loss: 0.2460, Test Loss: 0.5593, Test Acc: 0.8195
Epoch 216: Train Loss: 0.2472, Test Loss: 0.5550, Test Acc: 0.8202
Epoch 217: Train Loss: 0.2520, Test Loss: 0.5546, Test Acc: 0.8198
Epoch 218: Train Loss: 0.2478, Test Loss: 0.5544, Test Acc: 0.8180
Epoch 219: Train Loss: 0.2493, Test Loss: 0.5623, Test Acc: 0.8181
Epoch 220: Train Loss: 0.2479, Test Loss: 0.5555, Test Acc: 0.8193
Epoch 221: Train Loss: 0.2466, Test Loss: 0.5507, Test Acc: 0.8178
Epoch 222: Train Loss: 0.2487, Test Loss: 0.5569, Test Acc: 0.8199
Epoch 223: Train Loss: 0.2488, Test Loss: 0.5615, Test Acc: 0.8181
Epoch 224: Train Loss: 0.2478, Test Loss: 0.5548, Test Acc: 0.8170
Epoch 225: Train Loss: 0.2494, Test Loss: 0.5566, Test Acc: 0.8179
Epoch 226: Train Loss: 0.2486, Test Loss: 0.5576, Test Acc: 0.8185
Epoch 227: Train Loss: 0.2502, Test Loss: 0.5524, Test Acc: 0.8171
Epoch 228: Train Loss: 0.2463, Test Loss: 0.5557, Test Acc: 0.8192
Epoch 229: Train Loss: 0.2467, Test Loss: 0.5522, Test Acc: 0.8169
Epoch 230: Train Loss: 0.2469, Test Loss: 0.5539, Test Acc: 0.8182
Epoch 231: Train Loss: 0.2505, Test Loss: 0.5593, Test Acc: 0.8178
Epoch 232: Train Loss: 0.2508, Test Loss: 0.5571, Test Acc: 0.8192
Epoch 233: Train Loss: 0.2490, Test Loss: 0.5568, Test Acc: 0.8188
Epoch 234: Train Loss: 0.2496, Test Loss: 0.5565, Test Acc: 0.8189
Epoch 235: Train Loss: 0.2492, Test Loss: 0.5516, Test Acc: 0.8175
Epoch 236: Train Loss: 0.2475, Test Loss: 0.5557, Test Acc: 0.8190
Epoch 237: Train Loss: 0.2479, Test Loss: 0.5562, Test Acc: 0.8200
Epoch 238: Train Loss: 0.2488, Test Loss: 0.5511, Test Acc: 0.8179
Epoch 239: Train Loss: 0.2489, Test Loss: 0.5516, Test Acc: 0.8187
Epoch 240: Train Loss: 0.2492, Test Loss: 0.5560, Test Acc: 0.8196
Epoch 241: Train Loss: 0.2492, Test Loss: 0.5539, Test Acc: 0.8200
Epoch 242: Train Loss: 0.2491, Test Loss: 0.5540, Test Acc: 0.8183
Epoch 243: Train Loss: 0.2519, Test Loss: 0.5566, Test Acc: 0.8167
Epoch 244: Train Loss: 0.2475, Test Loss: 0.5568, Test Acc: 0.8181
Epoch 245: Train Loss: 0.2489, Test Loss: 0.5578, Test Acc: 0.8197
Epoch 246: Train Loss: 0.2507, Test Loss: 0.5514, Test Acc: 0.8188
Epoch 247: Train Loss: 0.2542, Test Loss: 0.5552, Test Acc: 0.8200
Epoch 248: Train Loss: 0.2485, Test Loss: 0.5541, Test Acc: 0.8185
Epoch 249: Train Loss: 0.2498, Test Loss: 0.5546, Test Acc: 0.8176
Epoch 250: Train Loss: 0.2473, Test Loss: 0.5528, Test Acc: 0.8187
Epoch 251: Train Loss: 0.2481, Test Loss: 0.5576, Test Acc: 0.8194
Epoch 252: Train Loss: 0.2467, Test Loss: 0.5608, Test Acc: 0.8168
Epoch 253: Train Loss: 0.2492, Test Loss: 0.5538, Test Acc: 0.8172
Epoch 254: Train Loss: 0.2502, Test Loss: 0.5556, Test Acc: 0.8176
Epoch 255: Train Loss: 0.2502, Test Loss: 0.5572, Test Acc: 0.8181
Epoch 256: Train Loss: 0.2496, Test Loss: 0.5600, Test Acc: 0.8178
conv1.weight: tensor([[[[ 4.0556e-01,  6.4611e-02,  8.3642e-01, -1.3526e-01,  1.7438e-01],
          [-5.3204e-01, -9.7872e-01, -4.4487e-01, -1.0097e+00, -6.6720e-02],
          [ 4.5165e-01, -1.1815e-01,  7.5363e-01, -9.8759e-02,  4.6645e-01],
          [ 9.1327e-03, -2.1608e-01,  3.6189e-01, -5.0918e-01,  2.8110e-01],
          [ 1.4958e-01, -4.3724e-02,  2.3945e-01, -2.0855e-01,  1.6221e-01]],

         [[ 3.2288e-01,  3.3068e-01,  8.3649e-01, -1.2315e-01,  1.7212e-01],
          [-3.2841e-01, -9.0764e-01, -4.2108e-01, -9.0330e-01,  6.4329e-02],
          [ 4.1939e-01,  9.5598e-02,  8.3000e-01, -2.5496e-01,  5.4932e-01],
          [ 4.5658e-02, -3.5996e-01,  4.5876e-01, -5.3906e-01,  2.9373e-01],
          [-1.4645e-02, -3.7736e-01,  1.8232e-01, -3.4230e-01, -2.2635e-02]],

         [[ 2.1652e-01,  1.8198e-01,  8.5601e-01,  3.1018e-03,  7.6898e-02],
          [-4.1613e-01, -1.0695e+00, -3.5716e-01, -7.4902e-01, -8.9262e-02],
          [ 5.7146e-01, -3.1842e-03,  7.1833e-01,  6.4821e-02,  2.0157e-01],
          [ 1.8063e-01, -2.8785e-01,  3.7847e-01, -3.5389e-01,  7.8930e-02],
          [ 9.6028e-05, -2.8763e-01,  2.1542e-01, -1.4569e-01,  4.9575e-02]]],


        [[[-3.4562e-01, -4.8468e-01, -3.8664e-01, -2.8240e-01, -3.2830e-01],
          [-2.6785e-01, -1.1261e-01,  1.8039e-01, -1.2405e-01, -2.0177e-01],
          [ 1.4014e-01,  4.4745e-01,  6.5551e-01,  3.6640e-01, -1.4451e-01],
          [ 2.3238e-01,  5.4202e-01,  7.6899e-01,  3.9069e-01, -1.2255e-01],
          [-6.0908e-02,  2.7020e-01,  4.6421e-01,  7.6055e-03, -2.4553e-01]],

         [[ 2.5075e-01,  2.2822e-02, -8.5669e-02,  8.2028e-03,  3.3261e-01],
          [-8.5612e-02, -1.9283e-01, -3.0956e-01, -2.2743e-01,  1.3484e-01],
          [-3.3693e-01, -5.8570e-01, -6.5959e-01, -2.8786e-01,  1.4728e-01],
          [-2.3765e-01, -4.2514e-01, -5.5715e-01, -3.3379e-01,  1.0140e-01],
          [ 1.1668e-01,  2.0315e-02, -3.9818e-02,  1.6212e-01,  2.7143e-01]],

         [[ 3.1778e-01,  4.7772e-01,  3.5200e-01,  2.2187e-01,  1.2660e-01],
          [ 2.9258e-01,  2.4570e-01,  1.3725e-01,  1.3833e-01,  3.6223e-02],
          [ 3.7373e-01,  1.0534e-01, -3.0248e-02,  4.1893e-02,  2.7768e-01],
          [-4.6446e-02, -2.8642e-01, -5.1545e-01, -3.1601e-01,  1.3893e-01],
          [-1.6159e-01, -3.4886e-01, -4.6554e-01, -9.3875e-02, -1.0446e-01]]],


        [[[-1.5372e-01, -2.9588e-02,  6.4182e-02, -4.6045e-01, -1.3169e-02],
          [ 1.4792e-01, -4.6197e-01,  2.5661e-01, -2.8557e-02, -2.6491e-01],
          [ 5.9010e-01, -2.1920e-01, -1.0132e+00,  3.8812e-01, -5.1908e-02],
          [ 1.9095e-01,  6.2650e-01, -3.9664e-01, -3.0406e-01,  1.3760e-02],
          [ 1.5697e-01,  3.2621e-01,  7.3912e-01, -1.7105e-01,  1.0499e-01]],

         [[-5.1280e-02,  2.1457e-01,  4.6998e-01, -4.2835e-02,  3.0202e-01],
          [-1.2168e-01, -2.8009e-01,  3.8837e-01,  2.6106e-01,  2.2414e-01],
          [ 1.7326e-01, -3.3522e-01, -1.0409e+00,  7.1390e-01,  2.3012e-01],
          [-2.8232e-01,  1.8498e-01, -5.4780e-01, -1.5915e-01,  3.2448e-01],
          [-6.1905e-01, -3.1109e-01,  5.1869e-02, -5.5901e-01, -1.4065e-02]],

         [[-1.3158e-01,  7.8835e-02,  2.6524e-01, -3.2185e-01, -6.5011e-02],
          [-2.2591e-01, -2.3200e-01,  4.6788e-01,  4.5319e-02, -2.0343e-01],
          [ 2.0710e-01, -4.4685e-02, -7.3049e-01,  5.6141e-01, -1.2984e-01],
          [-1.0781e-02,  5.8458e-01, -1.4080e-01, -1.1790e-01,  3.3137e-03],
          [-2.7767e-01,  2.4615e-02,  5.9820e-01, -1.0448e-01, -1.2154e-01]]],


        ...,


        [[[-3.8575e-01,  2.7809e-01, -3.1592e-02, -5.2276e-01,  2.1831e-01],
          [-1.1248e-02,  6.4336e-01, -1.3429e+00,  1.0959e-01,  3.9001e-01],
          [ 4.1789e-01, -7.6436e-01, -7.4708e-01,  1.3055e+00,  2.0260e-02],
          [-1.5848e-01, -7.4901e-01,  7.8752e-01,  4.8339e-01, -3.6957e-01],
          [-1.6691e-02,  2.1647e-01,  5.8296e-01, -3.4844e-01, -5.5663e-02]],

         [[ 1.8518e-01,  3.9997e-01,  7.3895e-02, -5.3150e-01,  7.8477e-02],
          [ 2.5022e-01,  7.3691e-01, -1.4046e+00,  8.9699e-02,  3.4802e-01],
          [ 5.0972e-01, -6.6236e-01, -7.9093e-01,  1.0948e+00, -2.0269e-01],
          [ 7.1917e-02, -7.7575e-01,  6.9086e-01,  2.2668e-01, -2.3629e-01],
          [-2.0917e-01, -4.9581e-02,  1.4772e-01, -2.8117e-01,  2.1659e-01]],

         [[-1.9744e-01,  3.7568e-01,  1.4044e-01, -2.8379e-01,  1.9329e-01],
          [-4.3679e-02,  7.7079e-01, -1.0911e+00,  4.1491e-02,  7.3932e-02],
          [ 5.2519e-01, -5.0281e-01, -5.9882e-01,  9.5160e-01, -3.3783e-01],
          [ 2.2117e-01, -6.5994e-01,  6.2190e-01,  9.8646e-02, -3.3166e-01],
          [-1.1901e-01,  1.1832e-03,  1.7488e-01, -2.7439e-01,  1.2169e-01]]],


        [[[-2.4841e-02,  5.8432e-02, -4.7503e-02, -1.5198e-01,  4.0332e-01],
          [-1.0879e-02,  4.7513e-01,  3.8828e-01, -8.0304e-01,  2.0014e-01],
          [-2.0205e-02, -1.0830e+00,  2.3132e-01,  1.2992e+00, -3.9661e-01],
          [ 2.2923e-02,  8.9468e-02, -6.2100e-01,  1.5926e-01, -1.3775e-01],
          [-2.8515e-01,  4.2403e-01,  2.6441e-01, -4.4298e-01,  6.3698e-02]],

         [[-1.7500e-01, -2.8672e-01, -4.5266e-01, -4.9838e-01, -2.0719e-01],
          [ 1.2618e-02,  1.9012e-01,  1.5022e-01, -1.0728e+00, -1.5788e-01],
          [ 4.3841e-01, -7.4076e-01,  2.5583e-01,  1.0882e+00, -5.1013e-01],
          [ 5.5872e-01,  5.7977e-01, -2.7575e-01,  2.1118e-01, -4.0963e-02],
          [-2.3872e-02,  6.0016e-01,  4.5862e-01, -1.2801e-01,  3.0163e-01]],

         [[ 4.4816e-02,  3.2467e-01,  1.7191e-01,  2.1349e-01,  7.1959e-01],
          [-3.4133e-02,  3.9032e-01,  5.2158e-01, -6.7069e-01,  4.8700e-01],
          [-1.1259e-01, -1.0230e+00,  1.7844e-01,  1.0192e+00, -4.8297e-01],
          [ 1.0406e-01, -3.3263e-02, -8.1547e-01,  1.1025e-02, -4.1755e-02],
          [-4.9203e-01, -3.0989e-02, -8.1491e-02, -6.4531e-01,  2.7459e-02]]],


        [[[-4.9039e-02,  9.1561e-02,  3.3080e-01,  2.5805e-01,  8.6372e-02],
          [ 1.2831e-01, -1.3892e-01,  3.1074e-01,  3.5427e-01,  9.2680e-02],
          [ 2.0946e-01, -4.3017e-01, -1.9333e-01,  4.6923e-01, -9.9523e-02],
          [ 1.2650e-01, -2.9726e-01, -3.1080e-01,  2.7311e-01,  2.0493e-01],
          [-1.8737e-01, -1.5482e-01, -4.0414e-01, -1.4424e-01,  6.9538e-02]],

         [[-2.5086e-01, -5.1697e-01, -1.7943e-01, -2.1255e-02,  2.9551e-01],
          [ 4.3826e-02, -6.7904e-01, -2.7668e-01,  9.8990e-02,  2.9062e-01],
          [ 2.8999e-01, -7.6370e-01, -3.9617e-01,  2.1353e-01,  2.8762e-01],
          [ 5.2265e-01, -4.5053e-01, -5.8944e-01,  2.6042e-01,  3.5077e-01],
          [ 3.4507e-01,  4.7435e-03, -4.1334e-01,  9.3177e-02,  3.6587e-01]],

         [[ 1.8027e-01, -6.3039e-03,  8.2352e-03,  7.3609e-03, -8.0313e-02],
          [ 2.3241e-01, -8.5601e-02, -9.1423e-02, -7.2674e-02, -3.7209e-01],
          [ 5.4366e-01, -1.3394e-01, -1.1166e-01,  4.7677e-02, -4.1479e-01],
          [ 6.3861e-01, -5.8099e-02, -2.8828e-01,  2.3358e-01, -1.0842e-01],
          [ 3.6023e-01,  3.5401e-01, -2.1319e-01,  6.7396e-02, -5.0099e-02]]]])
conv1.bias: tensor([-0.0244,  0.0014, -0.0163,  0.1097, -0.0405,  0.0466, -0.0338,  0.0841,
         0.0696,  0.0861,  0.0148, -0.0010,  0.0663, -0.0792,  0.0855,  0.0786,
         0.0935, -0.0806, -0.0974, -0.0346,  0.1067, -0.0159,  0.0574, -0.0956,
        -0.1024, -0.0143, -0.0919, -0.0977,  0.0730,  0.0023,  0.0558, -0.0331])
bn1.weight: tensor([1.1720, 0.9004, 0.7785, 1.2211, 1.2404, 1.1014, 1.3572, 1.1660, 1.1691,
        1.0986, 1.2200, 1.1956, 0.4348, 1.1500, 0.9969, 1.2945, 1.3319, 0.9957,
        0.9459, 0.7929, 1.1772, 1.2098, 0.8948, 0.6355, 1.0281, 1.6799, 0.7434,
        1.2413, 0.9429, 1.1110, 0.8359, 1.1902])
bn1.bias: tensor([ 0.0379, -0.5428, -0.0434, -0.1528, -0.6246, -0.4277, -0.7307, -0.6516,
        -0.4336, -0.7196, -0.9042, -0.1400,  0.0828, -0.1973, -0.0176, -0.9255,
        -0.9211, -0.2267, -0.2842, -0.3201, -0.7406, -0.1252, -0.0707, -0.1047,
        -0.1523, -0.3171, -0.1121, -0.3408,  0.0301, -0.2468, -0.2642, -0.4543])
conv2.weight: tensor([[[[ 1.6888e-01,  1.6668e-01,  1.3202e-02, -1.4524e-02, -7.6075e-02],
          [ 9.8131e-02, -9.0859e-02, -1.4412e-01, -2.3158e-02, -1.9697e-01],
          [-3.3077e-03, -1.2105e-01, -1.2447e-01,  9.9099e-02,  6.1879e-02],
          [ 1.5521e-01,  9.5515e-02, -6.3375e-02,  5.9344e-02, -4.8952e-02],
          [ 9.4215e-02,  6.0807e-02,  9.5476e-02,  1.4711e-02, -1.2420e-01]],

         [[ 4.8997e-02,  1.2616e-01, -1.7815e-02,  7.0623e-02,  1.3517e-01],
          [ 4.3486e-02,  5.6046e-02, -5.4939e-02,  2.5442e-02,  1.8343e-01],
          [-9.8596e-02, -6.2530e-02, -6.3478e-02, -5.9470e-02,  3.1842e-02],
          [-2.1826e-01, -1.3682e-01, -9.7934e-02, -7.2882e-02, -3.6010e-02],
          [-1.9993e-01, -1.2979e-01, -1.0415e-01, -4.0272e-02, -1.0222e-01]],

         [[-1.7557e-01, -5.0673e-02, -2.1166e-02,  8.3740e-02, -5.9953e-02],
          [-8.7148e-02, -2.6633e-01, -1.7382e-01, -1.5403e-02, -1.7641e-01],
          [-6.2699e-02,  8.4839e-02,  3.8245e-02,  1.1424e-01, -9.8142e-02],
          [ 6.4816e-02,  7.3640e-02,  1.5323e-02, -4.0561e-02, -7.6074e-02],
          [-6.9222e-02, -5.9731e-02,  1.2771e-01, -1.3343e-01, -9.8355e-02]],

         ...,

         [[-1.3470e-01, -1.0608e-01,  2.5974e-01,  4.7858e-02,  1.3817e-01],
          [-1.8065e-01, -3.6489e-02,  3.2708e-01, -7.7286e-03,  1.4869e-02],
          [-1.7448e-01, -1.1953e-01,  1.0213e-01,  1.4520e-01,  2.2228e-01],
          [-9.4810e-02, -7.3620e-02, -1.4311e-01,  1.7202e-01, -8.7275e-03],
          [-1.6914e-02, -3.0881e-01, -1.5541e-01,  1.7254e-01, -2.0753e-02]],

         [[ 7.2473e-03, -1.2146e-01, -7.9151e-02,  4.1075e-02, -1.1952e-01],
          [-2.5407e-02, -1.8926e-01, -1.5876e-01, -1.5977e-02, -9.5879e-03],
          [-1.8588e-02, -1.6391e-01, -8.3175e-02, -1.0949e-01,  2.7849e-02],
          [ 7.4688e-02,  1.8519e-02,  1.7333e-01, -4.9885e-03, -8.3905e-02],
          [ 9.6179e-02,  2.1388e-02,  1.4070e-01,  2.1363e-03, -1.5840e-02]],

         [[ 5.7047e-02, -6.6248e-02, -2.2995e-02,  8.7640e-02, -2.9281e-02],
          [ 4.8162e-02, -1.3548e-01, -3.1946e-02,  6.1345e-02, -7.3782e-02],
          [-1.1667e-02, -3.5484e-02, -2.0125e-02,  4.1887e-02,  1.0691e-01],
          [-8.4431e-02, -1.7711e-01,  7.2442e-02, -1.3457e-01,  3.2817e-02],
          [-1.3805e-01, -1.8615e-01,  3.4445e-02, -2.3094e-01,  3.7993e-02]]],


        [[[ 7.2695e-02,  2.6693e-02, -2.8928e-02,  8.8238e-02, -2.2075e-02],
          [-7.8572e-02, -3.8761e-02, -7.8526e-02, -1.9839e-01, -2.4218e-01],
          [-3.4431e-02,  1.4868e-01,  3.2467e-02,  5.2855e-03, -2.3078e-01],
          [ 2.8182e-02,  1.2413e-01,  6.4177e-02,  2.4411e-02, -1.9097e-01],
          [ 2.1436e-02,  1.5965e-01,  2.0380e-02,  1.0973e-01,  5.1272e-02]],

         [[ 2.6595e-02,  6.8354e-02,  7.3581e-02,  1.7914e-02,  1.9467e-01],
          [-1.3182e-01, -1.0770e-02,  6.5593e-02,  1.1915e-02,  3.0276e-02],
          [-2.0200e-01, -1.1057e-01,  3.9581e-02,  2.2773e-02, -2.8315e-02],
          [-1.3722e-02, -1.1019e-01, -1.5551e-01, -8.0669e-02, -8.2024e-02],
          [-3.4049e-02, -4.1668e-02, -1.0150e-01, -5.7104e-02,  1.2958e-01]],

         [[ 1.0807e-01,  1.2087e-01,  8.6368e-02, -1.3841e-02, -1.0811e-01],
          [ 2.9167e-01,  1.2499e-01,  5.4256e-02,  6.4964e-03,  7.8064e-03],
          [ 1.5189e-01,  1.2403e-01, -7.0570e-02, -8.4436e-02, -2.0086e-04],
          [ 1.7723e-01, -3.0069e-02, -9.1842e-02,  6.8847e-03,  1.4545e-01],
          [ 3.0943e-02, -5.5466e-02, -3.3281e-02,  1.2405e-01,  6.5174e-02]],

         ...,

         [[-5.6701e-02, -1.9970e-01,  1.1193e-01, -1.6058e-02,  2.2888e-01],
          [-1.7175e-01,  2.6695e-02,  1.8097e-01,  2.7151e-01,  1.6241e-01],
          [-1.8422e-01,  2.3973e-02,  2.6340e-01,  3.0416e-01,  2.9173e-01],
          [-4.4863e-02,  6.3381e-02,  6.1411e-02,  1.2450e-01,  2.9473e-02],
          [-1.5241e-02,  1.2305e-01, -1.0336e-02, -1.9887e-01, -1.0657e-01]],

         [[ 1.3649e-01, -4.3136e-02, -1.5299e-01, -2.1122e-01, -1.0473e-01],
          [ 2.2215e-01,  6.4781e-02,  7.5180e-02, -1.2942e-01, -4.3689e-02],
          [ 2.4753e-01,  1.4443e-01, -7.3820e-03, -4.3276e-02, -9.7398e-02],
          [ 1.2277e-01, -3.1048e-02, -3.1524e-02, -9.2573e-02,  8.0781e-02],
          [ 2.5751e-01,  1.8295e-01, -1.4846e-01, -1.1726e-01, -5.3078e-02]],

         [[ 1.2292e-01,  6.8468e-02,  9.3124e-02,  1.2313e-01, -1.2996e-02],
          [-1.6883e-01, -7.9135e-02, -9.5845e-02, -7.3387e-02, -3.3345e-02],
          [-1.3044e-02, -2.9226e-02, -1.0022e-01,  4.1763e-02,  2.3042e-02],
          [ 6.6717e-02,  2.8889e-02,  1.3983e-01,  9.3461e-02,  3.5584e-02],
          [-7.2071e-02,  2.7587e-02,  7.4258e-02,  1.1800e-01, -2.5233e-02]]],


        [[[ 4.9368e-02, -2.9498e-03, -2.6217e-01, -4.4252e-02, -1.7571e-01],
          [ 1.1264e-02,  1.3836e-02,  1.8582e-02, -7.1480e-02, -1.0655e-02],
          [ 9.8461e-02,  1.6919e-02,  4.2418e-02,  7.9222e-02, -1.4430e-02],
          [ 3.9034e-02,  1.4203e-01,  2.9568e-01,  8.7404e-02, -1.1881e-02],
          [ 1.3852e-02,  1.8736e-01,  8.6806e-02,  1.4302e-01, -1.4652e-01]],

         [[ 6.4195e-02,  3.4155e-02,  5.0586e-02, -7.7577e-02, -4.8499e-02],
          [-2.4777e-02,  7.1244e-02,  4.9264e-02, -9.5743e-02, -6.5262e-02],
          [ 2.0765e-02,  9.6765e-02,  1.1696e-01, -3.3139e-02,  7.7469e-03],
          [-1.4851e-02,  8.5273e-02, -1.2187e-02, -9.5019e-03, -4.8844e-02],
          [-1.1902e-01, -1.1279e-01, -7.5470e-02, -8.8801e-02, -7.7355e-02]],

         [[ 1.4736e-01,  1.6987e-01,  1.3626e-01,  1.3074e-01,  1.9198e-01],
          [ 6.8104e-02,  3.0890e-02, -9.7583e-02,  1.8170e-01,  8.3454e-02],
          [ 1.0677e-01,  4.9985e-02,  6.3708e-02, -3.7699e-02,  2.1117e-02],
          [-3.9849e-02,  9.1656e-02, -1.0780e-01,  1.5296e-02, -1.6117e-02],
          [ 1.3892e-01, -5.4711e-02, -2.3127e-02, -5.8533e-02,  2.1498e-02]],

         ...,

         [[ 8.4176e-02, -1.2144e-01, -1.8182e-02, -1.1387e-01, -2.1595e-02],
          [-5.7850e-02, -1.1509e-01, -7.0690e-02,  1.9493e-01,  2.6152e-02],
          [-7.8652e-02, -1.2783e-01, -2.1235e-02,  1.2545e-01, -3.4219e-02],
          [-1.6101e-01,  4.9966e-02,  1.3310e-01,  1.0249e-01, -3.5394e-02],
          [ 1.9130e-02, -1.4938e-01,  2.3195e-01,  9.5124e-02,  2.3934e-01]],

         [[-1.1474e-01, -6.8284e-02,  1.5332e-02, -2.3110e-03,  5.1652e-02],
          [ 1.4491e-02,  5.1488e-03, -8.6547e-02,  6.0648e-02,  6.5372e-03],
          [-1.0192e-01,  3.0222e-02,  4.9562e-02,  1.9891e-02,  1.4415e-02],
          [-1.6313e-01, -1.2270e-02, -9.4931e-02,  7.7373e-03,  1.2648e-01],
          [-2.3633e-02, -5.3894e-02, -2.2100e-02,  1.4197e-02, -1.4463e-02]],

         [[-7.3721e-02, -2.3898e-02,  3.0493e-02, -1.7248e-01,  7.1898e-02],
          [-7.6825e-02, -1.2272e-01, -1.2945e-01, -7.7379e-02,  6.4000e-02],
          [-4.0514e-02, -1.1220e-02,  1.2068e-04, -9.9660e-03,  1.4063e-02],
          [-1.3599e-01, -1.1768e-02, -9.9231e-02, -3.6904e-02, -1.2006e-01],
          [-9.7192e-02, -7.6745e-03,  1.3354e-01,  3.0733e-02,  1.4775e-02]]],


        ...,


        [[[-3.4739e-02,  4.8683e-02,  1.1253e-01, -6.1972e-03, -1.1152e-01],
          [-9.7459e-02, -3.5190e-03,  3.0430e-02, -1.5965e-01, -1.1121e-01],
          [-1.3766e-01, -7.7584e-02, -1.6984e-01, -2.2909e-01, -1.7686e-01],
          [-2.2988e-02, -4.5790e-02, -2.0428e-01, -2.3612e-01, -2.3541e-01],
          [-1.0212e-01,  1.3255e-03, -9.3237e-02, -9.4822e-02, -1.3584e-01]],

         [[-5.6863e-02,  1.2178e-03,  4.4358e-02,  4.7092e-02,  9.8608e-02],
          [-3.0623e-03,  4.8885e-02,  2.2802e-01,  1.0662e-01, -2.7326e-02],
          [-1.0292e-01, -6.0313e-02,  2.1427e-01,  1.6164e-01, -1.5922e-01],
          [-1.5474e-01,  3.6643e-02,  2.4742e-01,  1.0345e-01, -4.9886e-02],
          [ 2.5664e-03,  1.4509e-01,  7.0027e-02, -2.3965e-02, -1.3666e-01]],

         [[-1.7980e-02, -2.0452e-01,  2.2530e-02, -5.3082e-02,  1.9033e-02],
          [ 2.1694e-01, -6.5871e-03,  2.1188e-01, -4.0803e-03,  2.1424e-02],
          [ 1.0851e-01, -2.0090e-02, -1.4397e-02, -4.8847e-03, -1.2426e-01],
          [ 2.4344e-02,  1.1716e-01,  7.1362e-02,  2.1120e-02, -7.7049e-02],
          [-4.7461e-02, -2.2137e-01, -2.0626e-01, -9.6554e-03, -1.4146e-01]],

         ...,

         [[-2.1089e-01, -5.8120e-02, -1.2650e-01,  4.3240e-02,  5.1854e-02],
          [-1.1272e-01, -1.2154e-01,  3.2189e-02,  1.0611e-01,  4.9734e-02],
          [-1.0896e-01, -1.5710e-01, -1.1323e-01, -6.5905e-02,  6.0174e-02],
          [-1.3918e-02,  3.0770e-03, -1.0067e-01,  1.2960e-01,  2.5985e-02],
          [ 1.8487e-02, -2.2802e-02, -8.4780e-02,  4.3028e-02,  2.1070e-02]],

         [[-1.5495e-01, -2.1959e-01, -4.8285e-02, -3.5303e-02,  2.7935e-02],
          [ 1.3736e-01, -8.4318e-02,  8.5147e-02, -5.3349e-02,  1.2099e-01],
          [-1.7148e-02, -9.5970e-02, -3.5809e-02,  2.0773e-02, -1.1127e-01],
          [-5.3283e-02, -1.4281e-01,  7.1545e-02,  8.5198e-02, -1.3586e-01],
          [ 4.7157e-02, -6.5390e-02,  8.6295e-02,  1.5735e-01,  9.6075e-02]],

         [[-8.1664e-02,  1.6915e-01,  1.4929e-01,  1.1863e-02, -1.3580e-02],
          [-1.0136e-01,  7.4856e-02,  1.5670e-01,  1.0146e-01, -3.2618e-02],
          [-1.0307e-01,  1.2104e-01,  1.6359e-01,  1.4988e-01,  4.7218e-02],
          [-7.8125e-02,  7.8770e-02,  1.6013e-01,  9.9719e-02, -3.7690e-02],
          [-1.0651e-01, -1.6321e-01,  8.9416e-02, -4.2449e-02, -1.4381e-01]]],


        [[[ 4.6354e-02, -5.1484e-02,  1.2058e-01,  2.7040e-02,  1.8277e-02],
          [-8.6249e-03,  2.2331e-02, -4.9534e-03, -9.0161e-02,  4.8196e-02],
          [-5.8218e-02,  3.9272e-02,  1.8757e-01,  5.1501e-02,  5.4718e-02],
          [-3.1621e-02,  3.6805e-02,  8.4074e-03,  1.8548e-02,  1.1915e-01],
          [ 5.3099e-02, -5.5751e-02, -7.4786e-02,  8.7009e-02,  8.8449e-03]],

         [[ 6.8193e-02, -3.3975e-02, -7.1639e-02, -1.3222e-02, -4.6480e-03],
          [ 5.4292e-02, -3.4175e-02, -1.1177e-01, -2.2835e-02, -4.3115e-02],
          [-9.3876e-02, -1.3636e-01, -1.4881e-01, -7.9920e-03, -4.7133e-02],
          [ 5.4605e-02,  6.9623e-02, -2.9994e-02,  4.1132e-02, -9.6220e-02],
          [ 4.0304e-02,  7.8505e-02,  2.0613e-02, -3.5729e-02,  2.4303e-02]],

         [[-4.0942e-02, -7.6442e-02,  3.5612e-02,  5.3203e-03, -8.8590e-02],
          [-1.0567e-01, -7.5670e-02,  5.0977e-02,  6.9991e-02, -1.2069e-01],
          [-1.0861e-01, -1.3097e-02,  9.7246e-02,  1.3403e-01,  9.2246e-06],
          [ 5.1251e-02,  4.9594e-02, -1.8616e-02, -6.2972e-03, -3.8542e-02],
          [-4.7268e-03,  4.3130e-03, -1.9502e-02, -1.4207e-01, -1.3435e-01]],

         ...,

         [[-7.1711e-02,  4.4859e-02, -3.1076e-01, -1.8221e-02,  7.2473e-02],
          [-8.2298e-02, -8.0490e-02, -3.9911e-02,  4.4257e-02, -1.8352e-01],
          [-1.3664e-01, -3.8367e-02,  2.5200e-01,  1.6250e-01, -8.0969e-02],
          [-5.4418e-02,  1.1445e-01,  1.6659e-01, -4.7054e-02, -1.3641e-02],
          [-1.8271e-01,  5.5327e-02,  1.0705e-02, -5.7559e-02, -1.6455e-02]],

         [[ 3.7482e-02,  1.0852e-01,  4.5482e-03, -1.8367e-01, -5.7282e-02],
          [ 7.4992e-03, -1.2452e-02,  5.1679e-02,  2.9061e-02,  5.1149e-03],
          [-1.5599e-02, -9.5651e-02,  7.6919e-02,  2.3054e-02, -8.7276e-02],
          [-5.2744e-02,  3.5985e-03, -7.4945e-03, -3.6293e-02, -2.0740e-01],
          [ 6.5362e-02, -1.0279e-01, -3.3108e-02,  1.0177e-03, -6.7950e-02]],

         [[ 4.7706e-02, -4.7412e-02, -1.7617e-01, -2.5319e-01, -1.5132e-01],
          [ 2.3373e-02, -1.3318e-01, -6.1470e-02, -9.1045e-02,  6.8113e-02],
          [-6.1779e-02,  1.0392e-01,  1.0520e-01,  9.7907e-02,  1.7039e-01],
          [ 2.1104e-02,  9.8194e-02,  8.5595e-02,  6.0405e-02,  9.0998e-02],
          [ 1.1582e-02,  1.0913e-01,  5.9588e-02, -7.4436e-02,  2.1306e-02]]],


        [[[-1.8856e-02,  1.3698e-01,  6.7466e-02,  1.0583e-01,  6.9718e-02],
          [-7.5293e-02,  9.8022e-02,  6.7224e-02, -4.2584e-02, -9.3511e-02],
          [ 5.3523e-02, -9.4096e-03, -2.9328e-02, -4.2195e-02,  4.9326e-02],
          [-2.0447e-02, -8.1621e-02, -1.6378e-01, -2.0374e-01, -5.5639e-02],
          [-1.6278e-01, -2.2671e-01, -1.3502e-01, -1.7157e-01,  5.0277e-02]],

         [[ 1.6606e-02,  2.9098e-02, -9.5486e-02, -1.4082e-01, -6.0385e-02],
          [ 1.5890e-01,  7.4187e-02, -8.0177e-02, -6.1760e-02,  6.2934e-02],
          [ 6.7201e-02,  8.2246e-02,  1.2245e-02,  1.6869e-02,  1.3965e-01],
          [-4.8294e-02, -4.5198e-02,  1.7421e-02, -6.7973e-03,  3.7896e-02],
          [ 1.0502e-02, -7.2313e-02, -1.2084e-01, -1.3817e-01, -2.2505e-02]],

         [[ 7.4470e-02,  5.3027e-02,  4.8241e-02,  8.7110e-02, -1.3927e-01],
          [-1.6062e-04,  2.6878e-01,  1.3324e-01,  1.1997e-01,  1.3594e-01],
          [ 1.5334e-01,  1.6071e-02,  1.5407e-02, -6.9088e-02,  3.5603e-02],
          [ 7.9812e-02, -1.3009e-02, -8.0614e-02, -1.5287e-01, -5.3068e-02],
          [ 2.1117e-02, -6.1536e-02, -1.1195e-01, -3.1000e-02, -9.1451e-02]],

         ...,

         [[ 2.7276e-01, -1.0768e-01, -1.6196e-01, -2.4771e-02,  1.4402e-02],
          [-1.2274e-01,  2.8676e-01,  8.2193e-02,  9.2193e-02, -4.4816e-02],
          [ 1.7021e-01,  7.4093e-02, -6.0333e-02, -2.9658e-01, -1.4973e-01],
          [ 5.8611e-02, -2.4177e-01, -2.6624e-01, -1.2539e-01, -1.4098e-01],
          [ 5.4729e-02,  7.8756e-02,  1.0502e-01, -7.1620e-02,  5.6468e-02]],

         [[-3.7928e-02,  3.1417e-02, -4.8171e-02, -1.7840e-02, -2.5598e-01],
          [ 8.2794e-02,  8.6356e-02,  1.3700e-02, -1.1627e-01, -3.2090e-02],
          [ 4.1588e-02, -3.1509e-02, -7.8761e-02, -1.2244e-01,  2.3802e-02],
          [ 5.8097e-02,  1.3029e-01, -4.4127e-02, -7.8651e-02,  5.4126e-02],
          [ 4.1857e-02,  2.9110e-02, -7.5468e-02,  5.4665e-02, -8.1249e-02]],

         [[ 1.3408e-01,  1.2743e-01,  7.7005e-02,  5.1069e-02, -8.3929e-02],
          [-1.2799e-01,  5.3975e-02, -2.6984e-02, -6.5039e-03, -2.3135e-02],
          [-5.7905e-02, -8.4777e-02,  4.5579e-03, -1.9406e-02, -8.9014e-02],
          [-1.7103e-01, -3.7155e-02, -2.9758e-02,  1.8880e-02, -2.0824e-02],
          [-1.4062e-01,  4.0179e-02, -2.3798e-02,  1.1039e-01, -8.3138e-02]]]])
conv2.bias: tensor([-0.0125, -0.0073,  0.0316, -0.0226,  0.0319,  0.0331,  0.0236, -0.0227,
        -0.0166, -0.0258,  0.0316, -0.0283,  0.0192,  0.0089, -0.0088,  0.0277,
        -0.0118, -0.0009, -0.0320, -0.0181,  0.0148, -0.0093,  0.0334,  0.0263,
         0.0252, -0.0200,  0.0088, -0.0344,  0.0313, -0.0154,  0.0134, -0.0273,
        -0.0309, -0.0333,  0.0324, -0.0037,  0.0296, -0.0262,  0.0044, -0.0321,
        -0.0246,  0.0276, -0.0072, -0.0341, -0.0158,  0.0288,  0.0159, -0.0148,
         0.0252,  0.0296, -0.0140,  0.0002,  0.0184, -0.0273,  0.0353, -0.0283,
        -0.0245, -0.0190,  0.0152, -0.0243, -0.0328, -0.0204,  0.0145,  0.0038])
bn2.weight: tensor([1.0322, 0.7708, 0.9120, 0.8401, 0.7963, 0.7951, 0.7810, 0.9175, 0.7842,
        0.8324, 0.7490, 0.8815, 0.7479, 0.8615, 1.0321, 0.7520, 1.0345, 0.8219,
        1.2251, 1.1247, 0.8433, 1.0046, 0.8334, 0.7921, 0.9744, 0.7349, 1.2572,
        0.7665, 1.1231, 1.0006, 0.8211, 1.2554, 0.9406, 0.9098, 0.9552, 0.9029,
        0.8965, 0.8729, 0.8099, 0.8840, 0.8036, 0.9935, 1.0187, 1.0411, 0.7777,
        1.0399, 0.9194, 0.9878, 0.7778, 0.9002, 0.7404, 0.9706, 0.9798, 0.9394,
        1.0539, 0.7775, 0.8899, 0.8123, 0.8170, 1.0041, 0.9464, 1.1363, 0.8408,
        0.8044])
bn2.bias: tensor([-0.8158, -0.8331, -0.7380, -0.8160, -0.7423, -0.6453, -0.5456, -0.6838,
        -0.6439, -0.6708, -0.6977, -0.7021, -0.7593, -0.7386, -0.9829, -0.7181,
        -0.7456, -0.5812, -1.2142, -0.9776, -0.8616, -0.7843, -0.6360, -0.5160,
        -0.8974, -0.5398, -1.1798, -0.3963, -0.9945, -0.8717, -0.5700, -1.1819,
        -0.7190, -0.7847, -0.9903, -0.6259, -0.8986, -0.6785, -0.5825, -0.6015,
        -0.6684, -1.1799, -1.0068, -0.8875, -0.5549, -0.9269, -0.8047, -0.8767,
        -0.6840, -0.7646, -0.7028, -1.0298, -0.6914, -0.7897, -1.0496, -0.6163,
        -1.0397, -0.6632, -0.8604, -0.9777, -1.0469, -1.2378, -0.7161, -0.6112])
conv3.weight: tensor([[[[ 0.0102,  0.0126, -0.0090, -0.0111, -0.0169],
          [-0.0156, -0.0054, -0.0285, -0.0625, -0.0192],
          [-0.0507, -0.0481, -0.0231, -0.0436, -0.0261],
          [ 0.0179,  0.0103, -0.0013,  0.0112,  0.0162],
          [ 0.0433,  0.0596, -0.0162, -0.0270,  0.0183]],

         [[ 0.1370,  0.1190,  0.0419,  0.0630,  0.0348],
          [ 0.0443,  0.0174, -0.0229,  0.0081,  0.0112],
          [-0.0520, -0.0492, -0.0309, -0.0210,  0.0726],
          [ 0.0002, -0.0222, -0.0282,  0.0180,  0.0593],
          [-0.0127,  0.0006,  0.0060,  0.0031,  0.0414]],

         [[-0.0167, -0.0312, -0.0517, -0.0542, -0.0721],
          [-0.0184,  0.0293, -0.0068, -0.0135, -0.0235],
          [ 0.0072, -0.0513, -0.0735, -0.0298,  0.0108],
          [ 0.0926,  0.0002, -0.0310,  0.0222, -0.0363],
          [ 0.0536,  0.0356,  0.0061, -0.0167,  0.0391]],

         ...,

         [[-0.0315, -0.0210, -0.0113, -0.0466, -0.0239],
          [-0.0825, -0.0919, -0.0870, -0.0468, -0.0469],
          [-0.0550, -0.1164, -0.1004, -0.0260, -0.0826],
          [-0.0096, -0.0705, -0.0337,  0.0070, -0.0340],
          [-0.0160, -0.0425, -0.0323, -0.0046, -0.0311]],

         [[ 0.0323, -0.0227,  0.0143, -0.0026, -0.0048],
          [ 0.0390,  0.0632,  0.0721, -0.0287,  0.0353],
          [ 0.0352,  0.0875,  0.0549,  0.0059,  0.0530],
          [ 0.0478,  0.0124, -0.0035,  0.0273,  0.0641],
          [ 0.1019,  0.0521,  0.0469,  0.0074,  0.0100]],

         [[ 0.0131,  0.0419, -0.0296, -0.0152,  0.0011],
          [ 0.0016,  0.0672,  0.0172,  0.0208,  0.0549],
          [ 0.0374,  0.0247,  0.0029, -0.0066,  0.0074],
          [ 0.0251, -0.0136, -0.0093, -0.0283,  0.0349],
          [-0.0624, -0.0250,  0.0014, -0.0168,  0.0750]]],


        [[[-0.0079, -0.0283, -0.0272, -0.0137,  0.0068],
          [-0.0511, -0.0255, -0.0412,  0.0072,  0.0222],
          [-0.0717, -0.1358, -0.0321, -0.0660, -0.0424],
          [-0.0077, -0.0692, -0.0442, -0.0654,  0.0260],
          [ 0.0256, -0.0003, -0.0239, -0.0074,  0.0113]],

         [[ 0.0189,  0.0124,  0.0787,  0.0369,  0.0226],
          [-0.0564,  0.0050,  0.0525, -0.0017,  0.0084],
          [ 0.0052,  0.0380,  0.0838,  0.0260,  0.0156],
          [ 0.0865,  0.0687,  0.0613,  0.0737,  0.0276],
          [-0.0146, -0.0202, -0.0298,  0.0243, -0.0306]],

         [[ 0.0963,  0.0108,  0.0655,  0.0400, -0.0107],
          [ 0.0722,  0.0317,  0.0372,  0.0203, -0.0407],
          [-0.0046,  0.0160, -0.0664, -0.0651, -0.0827],
          [ 0.0367,  0.0236,  0.0167,  0.0484, -0.0596],
          [ 0.0230,  0.0453,  0.0363,  0.0688, -0.0178]],

         ...,

         [[ 0.0471,  0.0041,  0.0428,  0.0343,  0.0459],
          [ 0.0400,  0.0074,  0.0235,  0.0312,  0.0240],
          [ 0.0220, -0.0165,  0.0213,  0.0811,  0.0223],
          [ 0.0681,  0.0338,  0.0257, -0.0005,  0.0637],
          [ 0.0171, -0.0120, -0.0046, -0.0269,  0.0325]],

         [[ 0.0576,  0.0300, -0.0291, -0.0008, -0.0421],
          [ 0.0245,  0.0481, -0.0132,  0.0689,  0.0086],
          [-0.0074,  0.0356, -0.0447,  0.0551, -0.0094],
          [ 0.0291,  0.0209, -0.0131,  0.0271, -0.0009],
          [-0.0204, -0.0029, -0.0500, -0.0180, -0.0066]],

         [[-0.0867, -0.0975, -0.0910, -0.0411, -0.0164],
          [-0.0097, -0.0363, -0.1093, -0.0612, -0.0196],
          [-0.0521, -0.0562, -0.0606, -0.0829, -0.0295],
          [-0.0510, -0.0112, -0.0029,  0.0013, -0.0206],
          [-0.0314,  0.0107,  0.0066, -0.0126, -0.0166]]],


        [[[-0.0037, -0.0467, -0.0164,  0.0027, -0.0062],
          [-0.0434, -0.0203, -0.0153, -0.0654, -0.0138],
          [ 0.0064, -0.0265, -0.0041, -0.0443, -0.0477],
          [-0.0189, -0.0016,  0.0243, -0.0181, -0.0186],
          [-0.0393, -0.0150, -0.0406, -0.0903, -0.0175]],

         [[-0.0361, -0.0629, -0.0733, -0.0595,  0.0037],
          [ 0.0376, -0.0105, -0.0653, -0.0423, -0.0173],
          [ 0.0347, -0.0213, -0.0825, -0.0757, -0.0626],
          [-0.0160, -0.0245, -0.0486, -0.0156, -0.0422],
          [ 0.0360,  0.0397,  0.0921,  0.0770,  0.0447]],

         [[ 0.0084, -0.0090, -0.0016, -0.0203, -0.0267],
          [ 0.0094, -0.0073, -0.0502,  0.0034, -0.0153],
          [ 0.0349,  0.0300, -0.0303,  0.0307, -0.0561],
          [ 0.0572, -0.0011, -0.0122,  0.0320, -0.0044],
          [ 0.0236,  0.0918, -0.0038,  0.0391, -0.0241]],

         ...,

         [[-0.0204, -0.0159, -0.0087, -0.0690, -0.0416],
          [-0.0222, -0.0462, -0.0033,  0.0095, -0.0415],
          [-0.0616,  0.0127, -0.0395, -0.0057, -0.0250],
          [ 0.0174,  0.0051, -0.0388,  0.0176, -0.0120],
          [-0.0188, -0.0219, -0.0400, -0.0595, -0.0744]],

         [[-0.0396, -0.0269,  0.0198, -0.0019,  0.0215],
          [-0.0408,  0.0127,  0.0045,  0.0602,  0.0099],
          [-0.0429, -0.0525, -0.0246,  0.0122,  0.0073],
          [-0.0208,  0.0289,  0.0255,  0.0522, -0.0201],
          [ 0.0464,  0.0049, -0.0007,  0.0501, -0.0525]],

         [[ 0.0039, -0.0446, -0.0497, -0.0789, -0.0539],
          [ 0.0165,  0.0153, -0.0146, -0.0558, -0.0480],
          [ 0.0312,  0.0576,  0.0543,  0.0186,  0.0037],
          [ 0.0714,  0.0628,  0.0388,  0.0170,  0.0232],
          [ 0.0359,  0.0358,  0.0217, -0.0045,  0.0220]]],


        ...,


        [[[ 0.0779,  0.0652,  0.0147, -0.0228,  0.0751],
          [ 0.0174,  0.0744, -0.0211,  0.0367,  0.0637],
          [ 0.0002,  0.0912,  0.0354,  0.0268,  0.0444],
          [ 0.0200,  0.1186,  0.0756,  0.0426,  0.0338],
          [-0.0015, -0.0033,  0.1067,  0.0292, -0.0065]],

         [[-0.0775, -0.0759, -0.0792, -0.0790, -0.0695],
          [-0.0197, -0.0446, -0.0434, -0.0243, -0.0122],
          [-0.0111, -0.0650, -0.0298, -0.0599,  0.0079],
          [-0.0230, -0.0273, -0.0709, -0.0106, -0.0223],
          [-0.0242,  0.0019, -0.0277,  0.0239, -0.0548]],

         [[-0.1064, -0.0786, -0.0350, -0.0648, -0.0305],
          [-0.0252, -0.0265, -0.0065, -0.0389, -0.0209],
          [ 0.0062,  0.0908,  0.0177, -0.0206, -0.0211],
          [ 0.0495,  0.0887, -0.0201, -0.0718, -0.0290],
          [ 0.0484,  0.0177, -0.0412, -0.0253,  0.0101]],

         ...,

         [[-0.0364, -0.0490, -0.0048,  0.0157, -0.0308],
          [-0.0730, -0.0829, -0.0572,  0.0447,  0.0187],
          [-0.0228, -0.0772, -0.0746, -0.0572, -0.0253],
          [ 0.0192, -0.0761, -0.0943, -0.1122, -0.0101],
          [ 0.0042,  0.0309,  0.0407,  0.0514,  0.0269]],

         [[ 0.0012,  0.0211,  0.0354, -0.0309, -0.0453],
          [-0.0222, -0.0247,  0.0228, -0.0111, -0.0545],
          [-0.0542, -0.0314, -0.0056, -0.0101, -0.0731],
          [-0.0179, -0.0329, -0.0392, -0.0452, -0.0372],
          [-0.0794, -0.0790, -0.0648, -0.1055, -0.1126]],

         [[ 0.0285,  0.0197, -0.0176, -0.0189, -0.0060],
          [-0.0371,  0.0030,  0.0444,  0.0244, -0.0054],
          [-0.0147,  0.0228,  0.0541,  0.0556,  0.0767],
          [ 0.0012, -0.0094,  0.0188,  0.0289,  0.0188],
          [-0.0268, -0.0354,  0.0014, -0.0514, -0.0157]]],


        [[[-0.0771, -0.0052,  0.0168,  0.0193, -0.0207],
          [-0.0219,  0.0185,  0.0074, -0.0629, -0.0369],
          [ 0.0061, -0.0290,  0.0080, -0.0598, -0.0558],
          [ 0.0154, -0.0197,  0.0160, -0.0209, -0.0205],
          [-0.0208, -0.0095, -0.0518, -0.0141, -0.0338]],

         [[ 0.0091,  0.0329, -0.0282, -0.0472, -0.0046],
          [ 0.0389, -0.0105, -0.0389, -0.0583,  0.0036],
          [ 0.0143,  0.0104, -0.0129,  0.0023,  0.0123],
          [ 0.0110, -0.0730, -0.0276, -0.0014, -0.0130],
          [ 0.0411,  0.0265,  0.0365,  0.0350,  0.0787]],

         [[ 0.0368, -0.0095,  0.0787,  0.0637,  0.0408],
          [ 0.0563,  0.0051,  0.0414,  0.0499,  0.0309],
          [ 0.0441,  0.0243,  0.0250,  0.0464,  0.0017],
          [ 0.0674, -0.0013,  0.0129,  0.0277,  0.0246],
          [ 0.0438, -0.0439, -0.0178, -0.0201,  0.0149]],

         ...,

         [[-0.0436, -0.0450, -0.0463, -0.0583, -0.0261],
          [-0.0194, -0.0226, -0.0080, -0.0343, -0.0346],
          [-0.0050, -0.0337, -0.0141,  0.0261, -0.0090],
          [ 0.0131,  0.0219, -0.0140, -0.0117,  0.0281],
          [-0.0206, -0.0687, -0.0029, -0.0637, -0.0025]],

         [[-0.0317, -0.0192,  0.0424, -0.0043, -0.0529],
          [-0.0387, -0.0184,  0.0406,  0.0117, -0.0206],
          [-0.0276, -0.0449,  0.0188, -0.0316, -0.0375],
          [-0.0018,  0.0198, -0.0013, -0.0413, -0.0785],
          [-0.0161, -0.0088,  0.0195,  0.0074, -0.0157]],

         [[ 0.0481,  0.0315, -0.0287,  0.0290, -0.0150],
          [ 0.0375,  0.0524,  0.0055,  0.0568,  0.0320],
          [ 0.0242, -0.0366, -0.0319,  0.0126,  0.0225],
          [ 0.0388, -0.0324, -0.0946, -0.0494, -0.0281],
          [ 0.0182, -0.0025,  0.0059, -0.0048,  0.0440]]],


        [[[ 0.0325, -0.0764, -0.0126, -0.0309, -0.0727],
          [ 0.0215, -0.0765, -0.0140, -0.0461, -0.0649],
          [-0.0193, -0.0644,  0.0120, -0.0328, -0.0371],
          [ 0.0010, -0.0078,  0.0507,  0.0821,  0.0769],
          [ 0.0232,  0.0710,  0.1383,  0.0825,  0.0834]],

         [[ 0.0387,  0.0354, -0.0093, -0.0256, -0.0232],
          [-0.0036,  0.0465,  0.0450,  0.0129, -0.0316],
          [-0.0189,  0.0846,  0.0254, -0.0080, -0.0296],
          [-0.0281,  0.0202, -0.0025, -0.0118, -0.0395],
          [-0.0309, -0.0173,  0.0259, -0.0238, -0.0121]],

         [[ 0.0252,  0.0361, -0.0294, -0.0658, -0.0259],
          [ 0.0127, -0.0049, -0.0788, -0.0436, -0.0700],
          [-0.0439, -0.0158, -0.0637, -0.0058, -0.0198],
          [ 0.0179, -0.0109, -0.0697,  0.0202,  0.0571],
          [-0.0223, -0.0351, -0.0047,  0.0095,  0.0065]],

         ...,

         [[ 0.0255, -0.0210,  0.0013,  0.0272, -0.0095],
          [-0.0053,  0.0053,  0.0318,  0.0176,  0.0109],
          [ 0.0361, -0.0183,  0.0234,  0.0083,  0.0073],
          [ 0.0711, -0.0040, -0.0067, -0.0003, -0.0357],
          [ 0.0327,  0.0068,  0.0097,  0.0111, -0.0601]],

         [[ 0.0299,  0.0689,  0.0475, -0.0112, -0.0024],
          [-0.0376,  0.0402,  0.0145, -0.0335, -0.0337],
          [-0.0856,  0.0102,  0.0478, -0.0270, -0.0757],
          [-0.0619,  0.0055, -0.0135, -0.0413, -0.0374],
          [-0.0282, -0.0034, -0.0255, -0.0644, -0.0349]],

         [[-0.0152, -0.0138, -0.0309, -0.0673, -0.1267],
          [ 0.0170, -0.0068, -0.0124,  0.0025, -0.0766],
          [ 0.0600, -0.0266, -0.0405,  0.0064, -0.0186],
          [-0.0285, -0.0299,  0.0186,  0.0144, -0.0649],
          [-0.0566, -0.0951, -0.0023, -0.0166, -0.0374]]]])
conv3.bias: tensor([ 8.2362e-03, -1.7266e-02, -1.2699e-02,  5.0417e-03, -1.7477e-02,
         9.8737e-04,  1.7999e-02, -1.2951e-02,  1.2128e-02,  9.7709e-03,
         1.1916e-02, -2.2607e-02, -9.3507e-03,  1.7299e-02, -7.0952e-03,
        -2.3666e-02, -1.9548e-02,  2.1902e-02, -4.1885e-03, -1.5691e-02,
         2.0768e-02, -2.1505e-02,  1.0792e-02,  1.0811e-02, -2.4869e-02,
         1.2911e-02, -1.9953e-02,  1.4440e-02,  8.0833e-04, -1.3719e-02,
         1.0042e-02, -1.5127e-02, -9.6177e-03,  1.0538e-02, -2.0468e-02,
        -2.1050e-02,  1.5285e-03, -1.1145e-02, -2.2178e-02, -1.6023e-02,
         1.7504e-03, -2.0357e-02, -3.1745e-03,  2.2879e-02,  2.1265e-02,
         1.7158e-02, -2.3733e-02,  1.7324e-02,  1.2763e-02, -9.8902e-03,
        -2.0558e-02, -6.1089e-03, -3.2034e-03, -1.3872e-02, -2.4228e-02,
         6.4673e-03,  1.4581e-02,  7.0572e-03,  1.3078e-02, -5.2948e-03,
         1.1287e-02, -1.2745e-03,  2.2163e-02, -1.7949e-02, -8.6538e-03,
        -2.4509e-02, -8.1895e-03, -1.3564e-02,  5.5075e-03,  1.4518e-02,
         8.0792e-03,  1.5885e-02,  1.6841e-02, -1.0136e-02, -5.5741e-05,
        -1.5276e-02, -1.6653e-02,  2.4858e-03,  1.0859e-02, -5.8021e-03,
        -2.4687e-02,  2.5421e-03, -1.0341e-02,  2.4845e-03,  1.9496e-02,
        -2.8603e-03, -2.3781e-02, -5.6790e-03,  7.3503e-03,  5.3057e-03,
        -1.4506e-02, -1.0517e-02, -1.7717e-02, -2.2767e-02,  9.5011e-04,
        -1.1869e-02, -6.9863e-04,  1.7594e-02, -2.2457e-02, -1.7119e-02,
         8.1281e-03,  1.3262e-02, -4.4957e-03,  3.6338e-03, -7.8373e-04,
         9.1430e-03, -1.4006e-02,  2.2425e-02, -2.1708e-02,  2.3781e-02,
         1.2775e-03, -1.3542e-03, -2.1705e-02,  2.3091e-02,  1.8492e-02,
        -1.3838e-02,  2.1268e-02,  1.5530e-02, -1.9926e-03,  3.5723e-03,
        -8.0736e-03,  1.7312e-02,  1.2764e-02,  9.1377e-03, -9.6453e-03,
         1.8361e-02,  1.3690e-02,  2.0985e-02])
bn3.weight: tensor([1.0954, 1.1931, 1.1721, 1.2046, 1.1777, 1.2899, 1.1025, 1.2224, 1.1280,
        1.2605, 1.3257, 1.1179, 1.1715, 1.2355, 1.0317, 1.2066, 1.2673, 1.2047,
        1.2462, 1.1719, 1.2107, 1.1835, 1.1742, 1.2876, 1.2934, 1.2579, 1.1676,
        1.1695, 1.1083, 1.1762, 1.2317, 1.3377, 1.1212, 1.2610, 1.1705, 1.2331,
        1.1158, 1.0669, 1.3635, 1.2466, 1.3007, 1.1506, 1.2067, 1.1981, 1.2275,
        1.1261, 1.2266, 1.1953, 1.1955, 1.1981, 1.1600, 1.2330, 1.0688, 1.2672,
        1.2368, 1.2721, 1.1920, 1.2547, 1.0944, 1.2584, 1.1464, 1.0975, 1.2101,
        1.3069, 1.2716, 1.1459, 1.1681, 1.1229, 1.2510, 1.3486, 1.1123, 1.1740,
        1.1316, 1.2290, 1.2337, 1.3029, 1.2204, 1.1508, 1.2041, 1.1438, 1.2742,
        1.3027, 1.1355, 1.2927, 1.2681, 1.2964, 1.2898, 1.2316, 1.2605, 1.2149,
        1.2859, 1.3962, 1.2284, 1.3179, 1.1596, 1.0978, 1.1839, 1.1495, 1.1664,
        1.2878, 1.0851, 1.2763, 1.3787, 1.1946, 1.2328, 1.2166, 1.2255, 1.2442,
        1.1861, 1.1812, 1.3945, 1.1850, 1.2172, 1.3356, 1.2493, 1.1918, 1.1807,
        1.0905, 1.2279, 1.1256, 1.2708, 1.2153, 1.2632, 1.1655, 1.1754, 1.2697,
        1.3439, 1.1253])
bn3.bias: tensor([-1.1304, -1.1526, -1.2463, -1.1496, -1.3408, -1.5082, -1.2407, -0.9243,
        -1.2517, -1.4440, -0.9625, -1.2161, -1.4498, -1.2954, -1.2486, -1.2235,
        -1.0825, -1.2343, -1.2267, -1.2756, -0.9501, -1.0608, -1.4528, -1.2691,
        -1.2058, -0.7835, -1.4389, -1.1713, -1.2972, -1.0462, -0.8402, -1.3528,
        -1.4060, -1.5166, -1.4158, -1.6484, -1.1642, -1.1573, -1.1925, -0.9450,
        -1.5030, -1.1977, -1.1152, -1.1485, -1.0876, -1.2484, -1.3226, -1.4193,
        -1.3096, -1.5902, -1.4102, -1.0939, -1.0918, -0.8256, -1.0855, -1.0148,
        -0.9922, -1.1273, -1.2084, -1.1759, -1.0594, -1.2149, -1.4200, -0.9011,
        -1.3636, -1.3298, -1.0705, -1.3021, -1.1548, -1.1353, -0.9832, -1.3012,
        -1.2613, -1.0349, -1.2079, -1.0813, -1.2322, -1.2080, -1.0718, -1.1639,
        -1.6057, -1.2283, -1.3879, -1.1127, -0.8672, -1.1775, -1.4376, -1.3736,
        -1.2747, -1.5075, -1.2998, -1.1011, -1.3042, -0.9194, -1.3844, -1.0114,
        -1.3370, -1.1391, -1.3060, -1.6840, -1.1120, -1.1712, -0.9279, -1.2259,
        -1.0084, -1.4868, -1.3190, -1.6436, -1.3041, -1.1286, -1.2997, -1.4660,
        -1.1269, -1.0363, -1.3015, -1.2129, -1.1116, -1.2216, -1.1303, -1.2694,
        -1.2841, -1.2760, -1.2141, -1.4351, -1.3559, -1.3767, -0.9814, -1.4216])
fc.weight: tensor([[ 0.3659,  0.3348,  0.3551,  ..., -0.5848, -0.8808,  0.1761],
        [-0.6616,  0.2823, -0.7657,  ...,  0.3812, -0.6301,  0.6111],
        [-0.0939,  0.1545, -0.9953,  ...,  0.7267,  0.4028, -0.4082],
        ...,
        [ 0.5876, -0.8518,  0.4860,  ...,  0.1725,  0.4472, -0.2248],
        [ 0.0407,  0.2916,  0.3784,  ..., -0.0050, -0.1381,  0.6021],
        [ 0.3283, -0.5819,  0.1318,  ...,  0.4733, -0.7705, -0.4100]])
fc.bias: tensor([ 0.3651, -0.9429,  0.2961,  0.1303,  0.3377, -0.5288,  0.4031,  0.1455,
        -0.0474, -0.2355])
